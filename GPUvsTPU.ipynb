{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPUvsTPU.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishita7078/test_tpu/blob/main/GPUvsTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QueVjeESsyKe"
      },
      "cell_type": "markdown",
      "source": [
        "# Why TPUs ?"
      ]
    },
    {
      "metadata": {
        "id": "5moeHHv4shGw"
      },
      "cell_type": "markdown",
      "source": [
        "TPUs are tensor processing units developed by Google to  accelerate operations on a Tensorflow Graph. Each TPU packs up to 180 teraflops of floating-point performance and 64 GB of high-bandwidth memory onto a single board. Here is a comparions between TPUs and Nvidia GPUs. The y axis represents # images per seconds and the x axis is different models.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/800/1*tVHGjJHJrhKaKECT3Z4CIw.png\" alt=\"Drawing\" style=\"width: 150px;\"/>"
      ]
    },
    {
      "metadata": {
        "id": "_SXoMcRs8aRs"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiement\n",
        "\n",
        "TPUs were only available on Google cloud but now they are available for free in Colab. We will be comparing TPU vs GPU here on colab using mnist dataset. We will compare the time of each step and epoch against different batch sizes."
      ]
    },
    {
      "metadata": {
        "id": "4ECTupP8warH"
      },
      "cell_type": "markdown",
      "source": [
        "# Downoad MNIST"
      ]
    },
    {
      "metadata": {
        "id": "oX7DOjhUlCLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521fc01d-e08a-4d2b-ed02-79a6ded58131"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def get_data():\n",
        "\n",
        "  #Load mnist data set\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "  x_train = x_train.astype('float32') / 255\n",
        "  x_test = x_test.astype('float32') / 255\n",
        "\n",
        "  x_train = np.expand_dims(x_train, 3)\n",
        "  x_test = np.expand_dims(x_test, 3)\n",
        "\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test  = to_categorical(y_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AtEJD_s1wdty"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic CNN"
      ]
    },
    {
      "metadata": {
        "id": "IaZZ2OwmwhKQ"
      },
      "cell_type": "markdown",
      "source": [
        "Note that since we need to run the code on TPU we need to do more work. We need to specify the address of the TPU and tell tensorflow to run the model on the TPU cluster"
      ]
    },
    {
      "metadata": {
        "id": "cUYn3VomnQDL"
      },
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def get_model(tpu = False):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  #add layers to the model\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  #compile the model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  #flag to run on tpu\n",
        "  if tpu:\n",
        "    #connect the TPU cluster using the address (TF2 equivalent)\n",
        "    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "\n",
        "    #run the model on different clusters (TF2 TPU strategy)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu_cluster_resolver)\n",
        "\n",
        "    #convert the model to run on tpu (rebuild under strategy scope)\n",
        "    with strategy.scope():\n",
        "      model = tf.keras.models.clone_model(model)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSoBDg4PwylQ"
      },
      "cell_type": "markdown",
      "source": [
        "#GPU vs TPU\n"
      ]
    },
    {
      "metadata": {
        "id": "yluf1xqjsILa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8c9e61-6405-4a7b-fc92-3b87d7cc2cbd"
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = get_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Wn9zXSBUw8m1"
      },
      "cell_type": "markdown",
      "source": [
        "Each time you want to run the model on TPU make sure to set the tpu flag and change the enviornment runtime via  Edit> Notebook Setting > Hardware Accelerator > TPU and then click save."
      ]
    },
    {
      "metadata": {
        "id": "4vAM7pBPxVbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26419f9-19c5-4f88-f674-e33185bcb36c"
      },
      "cell_type": "code",
      "source": [
        "#set tpu = True if you want to run the model on TPU\n",
        "model = get_model(tpu = False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_m67tWDhnm7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8345a123-8f26-4dbf-91d1-0d7e69c49264"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=1024,\n",
        "         epochs=10,\n",
        "         validation_data=(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 523ms/step - accuracy: 0.5522 - loss: 1.3877 - val_accuracy: 0.9175 - val_loss: 0.2890\n",
            "Epoch 2/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 521ms/step - accuracy: 0.8920 - loss: 0.3457 - val_accuracy: 0.9546 - val_loss: 0.1561\n",
            "Epoch 3/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 518ms/step - accuracy: 0.9307 - loss: 0.2260 - val_accuracy: 0.9660 - val_loss: 0.1103\n",
            "Epoch 4/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 518ms/step - accuracy: 0.9444 - loss: 0.1837 - val_accuracy: 0.9721 - val_loss: 0.0894\n",
            "Epoch 5/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 520ms/step - accuracy: 0.9536 - loss: 0.1504 - val_accuracy: 0.9774 - val_loss: 0.0731\n",
            "Epoch 6/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 519ms/step - accuracy: 0.9619 - loss: 0.1257 - val_accuracy: 0.9806 - val_loss: 0.0637\n",
            "Epoch 7/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 519ms/step - accuracy: 0.9644 - loss: 0.1150 - val_accuracy: 0.9818 - val_loss: 0.0557\n",
            "Epoch 8/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 519ms/step - accuracy: 0.9679 - loss: 0.1021 - val_accuracy: 0.9837 - val_loss: 0.0503\n",
            "Epoch 9/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 519ms/step - accuracy: 0.9711 - loss: 0.0964 - val_accuracy: 0.9847 - val_loss: 0.0476\n",
            "Epoch 10/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 524ms/step - accuracy: 0.9726 - loss: 0.0873 - val_accuracy: 0.9851 - val_loss: 0.0439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa929085fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "QGof6K46zXfq"
      },
      "cell_type": "markdown",
      "source": [
        "# Benchmarks\n",
        "\n",
        "Note that TPU setup takes some time when compiling the model and distributing the data in the clusters, so the first epoch will take alonger time. I only reported the time for the later epochs. I calculated the average time accross different epochs."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rR_h-pSwo2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4cbKs72g00sQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Epoch Time ($s$)"
      ]
    },
    {
      "metadata": {
        "id": "QNh64VMDz1Ks"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\left[\\begin{array}{c|c|c}  \n",
        " \\textbf{Batch Size} & \\textbf{GPU} & \\textbf{TPU} \\\\\n",
        " 256 & 6s & 6s\\\\  \n",
        " 512 & 5s & 3s\\\\\n",
        " 1024 & 4s & 2s\\\\\n",
        "\\end{array}\\right]$$"
      ]
    },
    {
      "metadata": {
        "id": "Q8eMm1GD1Mu5"
      },
      "cell_type": "markdown",
      "source": [
        "### Step Time ($\\mu s$)"
      ]
    },
    {
      "metadata": {
        "id": "q1hElmjr05Ah"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\left[\\begin{array}{c|c|c}  \n",
        " \\textbf{Batch Size} & \\textbf{GPU} & \\textbf{TPU} \\\\\n",
        " 256 & 94 \\mu s & 97 \\mu s\\\\  \n",
        " 512 & 82 \\mu  s& 58 \\mu s \\\\\n",
        " 1024 & 79 \\mu s & 37 \\mu s\\\\\n",
        "\\end{array}\\right]$$"
      ]
    },
    {
      "metadata": {
        "id": "J6eOKfyW38rN"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "*   https://qiita.com/koshian2/items/25a6341c035e8a260a01\n",
        "*   https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a\n",
        "*   https://blog.riseml.com/benchmarking-googles-new-tpuv2-121c03b71384\n",
        "*   https://cloudplatform.googleblog.com/2018/02/Cloud-TPU-machine-learning-accelerators-now-available-in-beta.html\n",
        "\n"
      ]
    }
  ]
}