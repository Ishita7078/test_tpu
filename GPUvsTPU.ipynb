{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPUvsTPU.ipynb",
      "provenance": [],
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishita7078/test_tpu/blob/main/GPUvsTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QueVjeESsyKe"
      },
      "cell_type": "markdown",
      "source": [
        "# Why TPUs ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ayz9_cDRMbsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f19d37-aa99-493b-d06f-d696810a48dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5moeHHv4shGw"
      },
      "cell_type": "markdown",
      "source": [
        "TPUs are tensor processing units developed by Google to  accelerate operations on a Tensorflow Graph. Each TPU packs up to 180 teraflops of floating-point performance and 64 GB of high-bandwidth memory onto a single board. Here is a comparions between TPUs and Nvidia GPUs. The y axis represents # images per seconds and the x axis is different models.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/800/1*tVHGjJHJrhKaKECT3Z4CIw.png\" alt=\"Drawing\" style=\"width: 150px;\"/>"
      ]
    },
    {
      "metadata": {
        "id": "_SXoMcRs8aRs"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiement\n",
        "\n",
        "TPUs were only available on Google cloud but now they are available for free in Colab. We will be comparing TPU vs GPU here on colab using mnist dataset. We will compare the time of each step and epoch against different batch sizes."
      ]
    },
    {
      "metadata": {
        "id": "4ECTupP8warH"
      },
      "cell_type": "markdown",
      "source": [
        "# Downoad MNIST"
      ]
    },
    {
      "metadata": {
        "id": "oX7DOjhUlCLb"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def get_data():\n",
        "\n",
        "  #Load mnist data set\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "  x_train = x_train.astype('float32') / 255\n",
        "  x_test = x_test.astype('float32') / 255\n",
        "\n",
        "  x_train = np.expand_dims(x_train, 3)\n",
        "  x_test = np.expand_dims(x_test, 3)\n",
        "\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test  = to_categorical(y_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtEJD_s1wdty"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic CNN"
      ]
    },
    {
      "metadata": {
        "id": "IaZZ2OwmwhKQ"
      },
      "cell_type": "markdown",
      "source": [
        "Note that since we need to run the code on TPU we need to do more work. We need to specify the address of the TPU and tell tensorflow to run the model on the TPU cluster"
      ]
    },
    {
      "metadata": {
        "id": "cUYn3VomnQDL"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.tpu.python.tpu import keras_support\n",
        "\n",
        "def get_model(tpu = False):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  #add layers to the model\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  #compile the model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  #flag to run on tpu\n",
        "  if tpu:\n",
        "    tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "\n",
        "    #connect the TPU cluster using the address\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "\n",
        "    #run the model on different clusters\n",
        "    strategy = keras_support.TPUDistributionStrategy(tpu_cluster_resolver)\n",
        "\n",
        "    #convert the model to run on tpu\n",
        "    model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSoBDg4PwylQ"
      },
      "cell_type": "markdown",
      "source": [
        "#GPU vs TPU\n"
      ]
    },
    {
      "metadata": {
        "id": "yluf1xqjsILa"
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wn9zXSBUw8m1"
      },
      "cell_type": "markdown",
      "source": [
        "Each time you want to run the model on TPU make sure to set the tpu flag and change the enviornment runtime via  Edit> Notebook Setting > Hardware Accelerator > TPU and then click save."
      ]
    },
    {
      "metadata": {
        "id": "4vAM7pBPxVbm"
      },
      "cell_type": "code",
      "source": [
        "#set tpu = True if you want to run the model on TPU\n",
        "model = get_model(tpu = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_m67tWDhnm7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "59645203-25f4-4e4f-87a2-72da5fa1cf48"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=1024,\n",
        "         epochs=10,\n",
        "         validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1639 - acc: 0.9513 - val_loss: 0.0677 - val_acc: 0.9752\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1345 - acc: 0.9573 - val_loss: 0.0552 - val_acc: 0.9808\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1189 - acc: 0.9619 - val_loss: 0.0443 - val_acc: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QGof6K46zXfq"
      },
      "cell_type": "markdown",
      "source": [
        "# Benchmarks\n",
        "\n",
        "Note that TPU setup takes some time when compiling the model and distributing the data in the clusters, so the first epoch will take alonger time. I only reported the time for the later epochs. I calculated the average time accross different epochs."
      ]
    },
    {
      "metadata": {
        "id": "4cbKs72g00sQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Epoch Time ($s$)"
      ]
    },
    {
      "metadata": {
        "id": "QNh64VMDz1Ks"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\left[\\begin{array}{c|c|c}  \n",
        " \\textbf{Batch Size} & \\textbf{GPU} & \\textbf{TPU} \\\\\n",
        " 256 & 6s & 6s\\\\  \n",
        " 512 & 5s & 3s\\\\\n",
        " 1024 & 4s & 2s\\\\\n",
        "\\end{array}\\right]$$"
      ]
    },
    {
      "metadata": {
        "id": "Q8eMm1GD1Mu5"
      },
      "cell_type": "markdown",
      "source": [
        "### Step Time ($\\mu s$)"
      ]
    },
    {
      "metadata": {
        "id": "q1hElmjr05Ah"
      },
      "cell_type": "markdown",
      "source": [
        "$$\\left[\\begin{array}{c|c|c}  \n",
        " \\textbf{Batch Size} & \\textbf{GPU} & \\textbf{TPU} \\\\\n",
        " 256 & 94 \\mu s & 97 \\mu s\\\\  \n",
        " 512 & 82 \\mu  s& 58 \\mu s \\\\\n",
        " 1024 & 79 \\mu s & 37 \\mu s\\\\\n",
        "\\end{array}\\right]$$"
      ]
    },
    {
      "metadata": {
        "id": "J6eOKfyW38rN"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "*   https://qiita.com/koshian2/items/25a6341c035e8a260a01\n",
        "*   https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a\n",
        "*   https://blog.riseml.com/benchmarking-googles-new-tpuv2-121c03b71384\n",
        "*   https://cloudplatform.googleblog.com/2018/02/Cloud-TPU-machine-learning-accelerators-now-available-in-beta.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(current_directory)\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "assert any(d.platform == \"tpu\" for d in jax.devices()), \"Not using TPU\"\n",
        "print(jax.devices())"
      ],
      "metadata": {
        "id": "EHzggtqFOwAA",
        "outputId": "95849e38-61a3-4a73-c22a-5b03ef589506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def _mvm_full(A, x):\n",
        "    return A @ x\n",
        "\n",
        "class TPUDenseMat:\n",
        "    \"\"\"\n",
        "    Wraps a real dense matrix A so `A @ x` runs on TPU via JAX.\n",
        "    Returns a numpy array, so the rest of the numpy model code remains unchanged.\n",
        "    \"\"\"\n",
        "    def __init__(self, A_np: np.ndarray, jax_dtype=jnp.float32):\n",
        "        A_np = np.asarray(A_np)\n",
        "        if A_np.ndim != 2 or A_np.shape[0] != A_np.shape[1]:\n",
        "            raise ValueError(f\"Expected square 2D matrix, got shape {A_np.shape}\")\n",
        "        self.N = int(A_np.shape[0])\n",
        "        self.jax_dtype = jax_dtype\n",
        "\n",
        "        self.A_dev = jax.device_put(jnp.asarray(A_np, dtype=jax_dtype))\n",
        "\n",
        "        x0 = jnp.zeros((self.N,), dtype=jax_dtype)\n",
        "        _ = _mvm_full(self.A_dev, x0).block_until_ready()\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return (self.N, self.N)\n",
        "\n",
        "    def __matmul__(self, x):\n",
        "        x_np = np.asarray(x)\n",
        "        if x_np.ndim != 1 or x_np.shape[0] != self.N:\n",
        "            raise ValueError(f\"Expected vector shape ({self.N},), got {x_np.shape}\")\n",
        "\n",
        "        x_dev = jax.device_put(jnp.asarray(x_np, dtype=self.jax_dtype))\n",
        "        y = _mvm_full(self.A_dev, x_dev)\n",
        "        y.block_until_ready()\n",
        "        return np.asarray(y)"
      ],
      "metadata": {
        "id": "-UxpO51gXZV2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "def _load_mat_any(path):\n",
        "    try:\n",
        "        return sio.loadmat(path)\n",
        "    except NotImplementedError:\n",
        "        import h5py\n",
        "\n",
        "        out = {}\n",
        "        with h5py.File(path, 'r') as f:\n",
        "            for k in f.keys():\n",
        "                out[k] = np.array(f[k])\n",
        "        return out\n",
        "\n",
        "\n",
        "def _load_mat_var(path, var_name=None):\n",
        "    d = _load_mat_any(path)\n",
        "    if var_name is not None:\n",
        "        if var_name not in d:\n",
        "            raise KeyError(f\"Variable '{var_name}' not found in {path}. Keys: {list(d.keys())}\")\n",
        "        return d[var_name]\n",
        "\n",
        "    keys = [k for k in d.keys() if not k.startswith('__')]\n",
        "    if len(keys) != 1:\n",
        "        raise KeyError(f\"Expected exactly one variable in {path}; found keys: {keys}\")\n",
        "    return d[keys[0]]\n",
        "\n",
        "\n",
        "def _load_txt_flat(path):\n",
        "    arr = np.loadtxt(path, delimiter=',')\n",
        "    return np.asarray(arr).reshape(-1)\n",
        "\n",
        "\n",
        "def initialize(load_trmult):\n",
        "    global H0, a, a_norm, m2, C_vect, tau0, pop0, pop5, pop5_fertadj, popminus5, popminus10, ubar\n",
        "    global trmult_reduced, n, earth_indices, indicator_sea, subs, beta, tail_bands, ind_islands\n",
        "    global alpha, theta, Omega, vect_omega\n",
        "\n",
        "    try:\n",
        "        H0 = _load_mat_var('H0.mat', 'H0')\n",
        "    except FileNotFoundError:\n",
        "        H0 = _load_mat_var('H0.mat', 'H0')\n",
        "\n",
        "    a = _load_mat_var('a_H0.mat', 'a_H0')\n",
        "    tau0 = _load_mat_var('tau_H0.mat', 'tau_H0')\n",
        "    m2 = _load_mat_var('m2.mat', 'm2')\n",
        "\n",
        "    a = np.asarray(a).reshape(-1)\n",
        "    tau0 = np.asarray(tau0).reshape(-1)\n",
        "    m2 = np.asarray(m2).reshape(-1)\n",
        "\n",
        "    a_norm = None\n",
        "\n",
        "    pop0 = _load_txt_flat('l.csv')\n",
        "    pop5 = _load_txt_flat('pop5.csv')\n",
        "    popminus5 = _load_txt_flat('popminus5.csv')\n",
        "    popminus10 = _load_txt_flat('popminus10.csv')\n",
        "    pop5_fertadj = _load_txt_flat('pop5_fertadj.csv')\n",
        "\n",
        "    H0_arr = np.asarray(H0)\n",
        "    earth_indices = np.flatnonzero(H0_arr.reshape(-1) > 0)\n",
        "    n = int(earth_indices.size)\n",
        "    indicator_sea = (H0_arr == 0)\n",
        "\n",
        "    ubar = _load_txt_flat('ubar.csv')\n",
        "    ubar[np.isnan(ubar)] = 0\n",
        "    ubar[np.isinf(ubar)] = 0\n",
        "\n",
        "    if load_trmult == 1:\n",
        "        trmult_reduced = _load_mat_var('drive/MyDrive/trmult_reduced.mat', 'trmult_reduced')\n",
        "        trmult_reduced = np.asarray(trmult_reduced)\n",
        "        trmult_reduced[trmult_reduced < 1e-12] = 0\n",
        "    else:\n",
        "        trmult_reduced = None\n",
        "\n",
        "    C = _load_txt_flat('C.csv')\n",
        "    C_stock = C[earth_indices]\n",
        "    indices = np.unique(C_stock)\n",
        "    C_stock_2 = C_stock.copy()\n",
        "    for i, idx in enumerate(indices, start=1):\n",
        "        C_stock_2[C_stock == idx] = i\n",
        "    C[earth_indices] = C_stock_2\n",
        "\n",
        "    subs = C.reshape(-1) + 1\n",
        "    C_vect = C[earth_indices]\n",
        "\n",
        "    beta = 0.965\n",
        "    tail_bands = 0.2\n",
        "    alpha = 0.06\n",
        "    theta = 6.5\n",
        "    Omega = 0.5\n",
        "\n",
        "    results = [\n",
        "        H0, a, a_norm, m2, C_vect, tau0, pop0, pop5, pop5_fertadj, popminus5, popminus10, ubar,\n",
        "        trmult_reduced, n, earth_indices, indicator_sea, subs, None, beta, tail_bands, None, alpha, theta, Omega\n",
        "    ]\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "B0o93t15Nq5b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from pathlib import Path\n",
        "\n",
        "def maps(series1, series2, series3, series4, t, earth_indices=None):\n",
        "    \"\"\"\n",
        "    Creates 4 maps at time t.\n",
        "    The series must be in order:\n",
        "    - series1: l(t)\n",
        "    - series2: u(t)\n",
        "    - series3: prod(t)\n",
        "    - series4: realgdp(t)\n",
        "    \"\"\"\n",
        "    if earth_indices is None:\n",
        "        from init import earth_indices as _earth_indices\n",
        "        earth_indices = _earth_indices\n",
        "\n",
        "    # Take logs of variables\n",
        "    series1 = np.log(series1)\n",
        "    series2 = np.log(series2)\n",
        "    series3 = np.log(series3)\n",
        "    series4 = np.log(series4)\n",
        "\n",
        "    # Define titles for the plots\n",
        "    titles = [\n",
        "        'Log population density, time {}'.format(t),\n",
        "        'Log utility, time {}'.format(t),\n",
        "        'Log productivity, time {}'.format(t),\n",
        "        'Log real GDP per capita, time {}'.format(t)\n",
        "    ]\n",
        "\n",
        "    # Define title names for saving files\n",
        "    title_names = ['PD', 'U', 'PR', 'RO']\n",
        "\n",
        "    # Plot each figure\n",
        "    for i, (series, title, title_name) in enumerate(zip([series1, series2, series3, series4], titles, title_names), start=1):\n",
        "        plt.figure()\n",
        "\n",
        "        # Create the map array\n",
        "        varm = np.full((180, 360), -np.inf)\n",
        "        varm.flat[earth_indices] = series\n",
        "\n",
        "        # Set color limits based on the series and time\n",
        "        if i == 1:\n",
        "            vmin, vmax = -10, 21\n",
        "        elif i == 3:\n",
        "            if t == 1:\n",
        "                vmin, vmax = -3, 7\n",
        "            elif t == 600:\n",
        "                vmin, vmax = 11, 21\n",
        "            else:\n",
        "                vmin, vmax = None, None\n",
        "        elif i == 4:\n",
        "            if t == 1:\n",
        "                vmin, vmax = -4, 3\n",
        "            else:\n",
        "                vmin, vmax = None, None\n",
        "        else:\n",
        "            vmin, vmax = None, None\n",
        "\n",
        "        # Plot the map\n",
        "        plt.imshow(varm, cmap='jet', vmin=vmin, vmax=vmax)\n",
        "        plt.colorbar(label='Value', orientation='vertical')\n",
        "        plt.title(title)\n",
        "\n",
        "        # Save the output to disk\n",
        "        Path('Maps').mkdir(parents=True, exist_ok=True)\n",
        "        filename = 'Maps/{}_NF_{}_1000.png'.format(title_name, t)\n",
        "        plt.savefig(filename)\n",
        "        plt.close()  # Close the figure to avoid memory issues\n"
      ],
      "metadata": {
        "id": "wWkAhF-kNrTn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import gamma\n",
        "\n",
        "def model(H, T, vars):\n",
        "    # Global variables (make sure these are initialized or imported correctly)\n",
        "    global a, a_norm, m2, ubar, C_vect, tau0, pop0, trmult_reduced, earth_indices, H0, n, alpha, theta, Omega\n",
        "    H0, a, a_norm, m2, C_vect, tau0, pop0, _, _, _, _, ubar, trmult_reduced, n, earth_indices, _, _, _, _, _, _, alpha, theta, Omega = vars\n",
        "\n",
        "    # Initialize parameters and output\n",
        "    # Normalize population to population density\n",
        "    H0_arr = np.asarray(H0).reshape(-1)\n",
        "    popdens = pop0.copy()\n",
        "    popdens[earth_indices] = popdens[earth_indices] / H0_arr[earth_indices]\n",
        "    popdens[np.isinf(popdens)] = 0\n",
        "    popdens[np.isnan(popdens)] = 0\n",
        "\n",
        "    # Parameter values\n",
        "    lbar = 5.9174e+09  # Total population\n",
        "    lambda_ = 0.32     # Congestion externalities\n",
        "    gamma1 = 0.319    # Elasticity of tomorrow's productivity w.r.t. today's innovation\n",
        "    gamma2 = 0.99246  # Elasticity of tomorrow's productivity w.r.t. today's productivity\n",
        "    eta = 1           # Parameter driving scale of technology diffusion\n",
        "    mu = 0.8          # Labor share in production\n",
        "    nu = 0.15         # Intercept parameter in innovation cost function\n",
        "    ksi = 125         # Elasticity of innovation costs w.r.t. innovation\n",
        "    sigma = 4         # Elasticity of substitution\n",
        "    rad = 6371        # Radius of Earth\n",
        "    psi = 1.8         # Subjective wellbeing parameter\n",
        "    khi = lambda_ - (alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta) / (1 + 2 * theta)\n",
        "    kappa1 = ((mu * ksi + gamma1) / ksi) ** (-(mu + gamma1 / ksi) * theta) * mu ** (mu * theta) * \\\n",
        "             (ksi * nu / gamma1) ** (-gamma1 / ksi * theta) * gamma(1 - (sigma - 1) / theta) ** (theta / (sigma - 1))\n",
        "\n",
        "    # Calculate utility from subjective wellbeing\n",
        "    u0 = np.exp(psi * ubar[earth_indices])\n",
        "\n",
        "    # Back out amenities\n",
        "    a_norm = a * u0\n",
        "\n",
        "    # Initialize output variables\n",
        "    l = np.zeros((n, T))\n",
        "    w = np.zeros((n, T))\n",
        "    phi = np.zeros((n, T))\n",
        "    realgdp = np.zeros((n, T))\n",
        "    tau = np.zeros((n, T))\n",
        "    u = np.zeros((n, T))\n",
        "    uhat = np.zeros((n, T))\n",
        "\n",
        "    # 2. Simulate the model\n",
        "\n",
        "    # Update productivity from period 0 to period 1 levels according to equations (8), (12), and (13)\n",
        "    avgprod = np.sum(tau0) / n\n",
        "    tau[:, 0] = eta * tau0 ** gamma2 * avgprod ** (1 - gamma2) * \\\n",
        "                (gamma1 / (nu * (gamma1 + mu * ksi)) * popdens[earth_indices]) ** (gamma1 * theta / ksi)\n",
        "\n",
        "    # Initial guess for uhat\n",
        "    uhat_loop = np.ones(n) / n\n",
        "\n",
        "    # Calculate equilibrium distribution for each period\n",
        "    for t in range(T):\n",
        "        print(f't={t + 1}')\n",
        "\n",
        "        # Solve for uhat using equation (51)\n",
        "        error = 1e+10\n",
        "\n",
        "        # Pre-computed quantities used in the while loop\n",
        "        aa = a_norm ** (theta ** 2 / (1 + 2 * theta))\n",
        "        aa2 = a_norm ** ((1 + theta) / ((khi / Omega + (1 + theta) / (1 + 2 * theta)) * (1 + 2 * theta)))\n",
        "        exponent_l = (1 - lambda_ * theta + (1 + theta) / (1 + 2 * theta) * (alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta))\n",
        "        input_integral_outer = aa * (H ** (theta / (1 + 2 * theta) - 1 + lambda_ * theta - (1 + theta) / (1 + 2 * theta) * (alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta))) * \\\n",
        "                               tau[:, t] ** ((1 + theta) / (1 + 2 * theta)) * m2 ** (-exponent_l / Omega)\n",
        "\n",
        "        input_integral_outer[np.isnan(input_integral_outer)] = 0\n",
        "        input_uhat_inner = H ** ((lambda_ - (alpha + (lambda_ + gamma1 / ksi - (1 - mu)) * theta) / (1 + 2 * theta)) / (khi / Omega + (1 + theta) / (1 + 2 * theta))) * \\\n",
        "                            tau[:, t] ** (1 / ((khi / Omega + (1 + theta) / (1 + 2 * theta)) * (1 + 2 * theta))) * \\\n",
        "                            m2 ** (khi / (Omega * (khi / Omega + (1 + theta) / (1 + 2 * theta))))\n",
        "        input_uhat_inner[H == 0] = 0\n",
        "\n",
        "        # Inner loop\n",
        "        while error >= 1e-2:\n",
        "            uhat_old = uhat_loop.copy()\n",
        "            input_integral_inner = input_integral_outer * uhat_loop ** (exponent_l / Omega - theta ** 2 / (1 + 2 * theta))\n",
        "            input_integral_inner[uhat_loop == 0] = 0\n",
        "\n",
        "            # Matrix product\n",
        "            rhs = np.dot(trmult_reduced, input_integral_inner)\n",
        "            eps_val = 1e-12\n",
        "            rhs = np.maximum(rhs, eps_val)\n",
        "\n",
        "            uhat_loop = aa2 * input_uhat_inner * rhs ** (1 / (khi * theta / Omega + theta * (1 + theta) / (1 + 2 * theta)))\n",
        "            error = np.sum((uhat_loop - uhat_old) ** 2)\n",
        "\n",
        "        uhat[:, t] = uhat_loop\n",
        "\n",
        "        # Solve for u using equation (53)\n",
        "        u[:, t] = uhat[:, t] / (lbar / np.sum(uhat[:, t] ** (1 / Omega) * m2 ** (-1 / Omega))) ** \\\n",
        "                  (Omega * (((1 / Omega) * (((lambda_ + (1 - mu) - gamma1 / ksi) * theta) - alpha) + theta) / theta - 1))\n",
        "\n",
        "        # Solve for population using equation (7)\n",
        "        l[:, t] = H ** -1 * u[:, t] ** (1 / Omega) * m2 ** (-1 / Omega)\n",
        "\n",
        "        # Rescale L so that H * L sums to lbar\n",
        "        l[:, t] = l[:, t] / np.sum(H * l[:, t]) * lbar\n",
        "\n",
        "        # Calculate other quantities\n",
        "        phi[:, t] = (gamma1 / (nu * (gamma1 + mu * ksi))) ** (1 / ksi) * l[:, t] ** (1 / ksi)\n",
        "        w[:, t] = a_norm ** (-theta / (1 + 2 * theta)) * u[:, t] ** (theta / (1 + 2 * theta)) * H ** (-1 / (1 + 2 * theta)) * \\\n",
        "                  tau[:, t] ** (1 / (1 + 2 * theta)) * l[:, t] ** ((alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta) / (1 + 2 * theta))\n",
        "\n",
        "        # Normalize wages relative to Princeton, NJ\n",
        "        w[:, t] = w[:, t] / w[3198, t]  # 3198 is the Python index for Princeton, NJ\n",
        "\n",
        "        # Calculate real GDP per capita using equation (22)\n",
        "        realgdp[:, t] = u[:, t] / a_norm * l[:, t] ** lambda_\n",
        "\n",
        "        # Calculate trade to GDP ratio in periods 1 and T\n",
        "        if t == 0 or t == T - 1:\n",
        "            print('TOTAL IMPORTS TO WORLD GDP')\n",
        "            trsharesum = np.dot(trmult_reduced, (tau[:, t] * l[:, t] ** (alpha - (1 - mu - gamma1 / ksi) * theta) * w[:, t] ** (-theta)))\n",
        "            eps_val = 1e-12\n",
        "            trsharesum = np.maximum(trsharesum, eps_val)\n",
        "            domtrade = 0\n",
        "            for i in range(n):\n",
        "                for j in range(n):\n",
        "                    if C_vect[i] == C_vect[j]:\n",
        "                        domtrade += (tau[j, t] * l[j, t] ** (alpha - (1 - mu - gamma1 / ksi) * theta) * w[j, t] ** (-theta) *\n",
        "                                     trmult_reduced[i, j] / trsharesum[i] * w[i, t] * H[i] * l[i, t])\n",
        "            print(1 - domtrade / np.sum(w[:, t] * H * l[:, t]))\n",
        "\n",
        "        # Update productivity according to equation (8)\n",
        "        if t < T - 1:\n",
        "            avgprod = np.sum(tau[:, t]) / n\n",
        "            tau[:, t + 1] = eta * tau[:, t] ** gamma2 * avgprod ** (1 - gamma2) * phi[:, t] ** (gamma1 * theta)\n",
        "\n",
        "    # Handle NaN values\n",
        "    realgdp[np.isnan(realgdp)] = 0\n",
        "    tau[np.isnan(tau)] = 0\n",
        "    phi[np.isnan(phi)] = 0\n",
        "    w[np.isnan(w)] = 0\n",
        "    l[np.isnan(l)] = 0\n",
        "\n",
        "    return l, w, u, tau, phi, realgdp\n"
      ],
      "metadata": {
        "id": "NkrWHx50NyAb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from math import gamma\n",
        "\n",
        "def backward(H, T, vars):\n",
        "    # Ensure global variables are available\n",
        "    global a_norm, m2, tau0, pop0, trmult_reduced, earth_indices, H0, n, alpha, theta, Omega\n",
        "    H0, a, a_norm, m2, _, tau0, pop0, _, _, _, _, ubar, trmult_reduced, n, earth_indices, _, _, _, _, _, _, alpha, theta, Omega = vars\n",
        "\n",
        "    # Initialize parameters and output\n",
        "    # Normalize population to population density\n",
        "    H0_arr = np.asarray(H0).reshape(-1)\n",
        "    popdens = np.copy(pop0)\n",
        "    popdens[earth_indices] = popdens[earth_indices] / H0_arr[earth_indices]\n",
        "    popdens[np.isinf(popdens)] = 0\n",
        "    popdens[np.isnan(popdens)] = 0\n",
        "\n",
        "    if a_norm is None:\n",
        "        psi = 1.8\n",
        "        u0 = np.exp(psi * ubar[earth_indices])\n",
        "        a_norm = np.asarray(a).reshape(-1) * u0\n",
        "\n",
        "    # Parameter values\n",
        "    lbar = 5.9174e+09\n",
        "    lambda_ = 0.32\n",
        "    gamma1 = 0.319\n",
        "    gamma2 = 0.99246\n",
        "    mu = 0.8\n",
        "    nu = 0.15\n",
        "    ksi = 125\n",
        "    sigma = 4\n",
        "    rad = 6371\n",
        "    khi = lambda_ - (alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta) / (1 + 2 * theta)\n",
        "    kappa1 = ((mu * ksi + gamma1) / ksi) ** (-(mu + gamma1 / ksi) * theta) * \\\n",
        "             mu ** (mu * theta) * (ksi * nu / gamma1) ** (-gamma1 / ksi * theta) * \\\n",
        "             gamma(1 - (sigma - 1) / theta) ** (theta / (sigma - 1))\n",
        "\n",
        "    # Initialize output variables\n",
        "    l = np.zeros((n, T))\n",
        "    u = np.zeros((n, T))\n",
        "    w = np.zeros((n, T))\n",
        "    phi = np.zeros((n, T))\n",
        "    tau = np.zeros((n, T))\n",
        "    realgdp = np.zeros((n, T))\n",
        "\n",
        "    # 2. Simulate the model backwards\n",
        "\n",
        "    # Initial guess for Lhat\n",
        "    l_loop = np.copy(popdens[earth_indices])\n",
        "\n",
        "    # Outer loop\n",
        "    for t in range(T):\n",
        "        print(f't={-t - 1}')\n",
        "\n",
        "        # Next period's productivity\n",
        "        if t > 0:\n",
        "            taunext = tau[:, t - 1]\n",
        "        else:\n",
        "            taunext = tau0\n",
        "\n",
        "        eps_val = 1e-12\n",
        "        eps_pos = 1e-300\n",
        "        taunext = np.asarray(taunext)\n",
        "        taunext = np.maximum(taunext, eps_pos)\n",
        "        taunext = np.minimum(taunext, 1e300)\n",
        "\n",
        "        # Solve for Lhat\n",
        "        error = 1e+10\n",
        "\n",
        "        # Pre-computed quantities used in the while loop\n",
        "        aa = a_norm ** (theta ** 2 / (1 + 2 * theta))\n",
        "        aa2 = a_norm ** ((1 + theta) / ((khi + Omega * (1 + theta) / (1 + 2 * theta) + theta / (1 + 2 * theta) * gamma1 / (ksi * gamma2)) * (1 + 2 * theta)))\n",
        "        exponent_l = (1 - lambda_ * theta + (1 + theta) / (1 + 2 * theta) * (alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta))\n",
        "        input_integral_outer = aa * H ** ((theta - theta ** 2 * Omega) / (1 + 2 * theta)) * \\\n",
        "                               taunext ** ((1 + theta) / (gamma2 * (1 + 2 * theta))) * \\\n",
        "                               m2 ** (-theta ** 2 / (1 + 2 * theta))\n",
        "        input_integral_outer[~np.isfinite(input_integral_outer)] = 0\n",
        "        denom_inner = (khi + Omega * (1 + theta) / (1 + 2 * theta) + theta / (1 + 2 * theta) * gamma1 / (ksi * gamma2))\n",
        "        input_l_inner = H ** (-(1 + Omega * (1 + theta)) / (denom_inner * (1 + 2 * theta))) * \\\n",
        "                        taunext ** (1 / (denom_inner * gamma2 * (1 + 2 * theta))) * \\\n",
        "                        m2 ** (-(1 + theta) / (denom_inner * (1 + 2 * theta)))\n",
        "        input_l_inner[H == 0] = 0\n",
        "        input_l_inner[~np.isfinite(input_l_inner)] = 0\n",
        "        input_l_inner = np.maximum(input_l_inner, 0)\n",
        "        input_l_inner = np.minimum(input_l_inner, 1e300)\n",
        "\n",
        "        # Inner loop - solve for l using equation (40)\n",
        "        it = 0\n",
        "        max_it = 2000\n",
        "        while error >= 1:\n",
        "            l_old = np.copy(l_loop)\n",
        "\n",
        "            l_loop = np.maximum(l_loop, eps_pos)\n",
        "            l_loop = np.minimum(l_loop, 1e300)\n",
        "\n",
        "            input_integral_inner = input_integral_outer * \\\n",
        "                                   l_loop ** (exponent_l - Omega * theta ** 2 / (1 + 2 * theta) - theta * (1 + theta) / (1 + 2 * theta) * gamma1 / (ksi * gamma2))\n",
        "            input_integral_inner[l_loop == 0] = 0\n",
        "            input_integral_inner[~np.isfinite(input_integral_inner)] = 0\n",
        "\n",
        "            # Matrix product\n",
        "            rhs = np.dot(trmult_reduced, input_integral_inner)\n",
        "            rhs = np.maximum(rhs, eps_val)\n",
        "\n",
        "            l_loop = aa2 * input_l_inner * rhs ** (1 / ((khi + Omega * (1 + theta) / (1 + 2 * theta) + theta / (1 + 2 * theta) * gamma1 / (ksi * gamma2)) * theta))\n",
        "            l_loop[~np.isfinite(l_loop)] = eps_pos\n",
        "            l_loop = np.minimum(l_loop, 1e300)\n",
        "            error = np.sum((l_loop - l_old) ** 2)\n",
        "            if not np.isfinite(error):\n",
        "                error = 0\n",
        "            it += 1\n",
        "            if it >= max_it:\n",
        "                error = 0\n",
        "\n",
        "        # Rescale L so that H * L sum to lbar\n",
        "        denom = np.sum(H * l_loop)\n",
        "        if (not np.isfinite(denom)) or denom <= eps_pos:\n",
        "            denom = eps_pos\n",
        "        l[:, t] = l_loop / denom * lbar\n",
        "\n",
        "        # Back out productivity using equation (39)\n",
        "        tau[:, t] = ((mu + gamma1 / ksi) / (gamma1 / ksi) * nu) ** (theta * gamma1 / (ksi * gamma2)) * \\\n",
        "                    taunext ** (1 / gamma2) * l[:, t] ** (-theta * gamma1 / (ksi * gamma2))\n",
        "        avgprodtogamma2 = np.sum(tau[:, t]) / n\n",
        "        tau[:, t] = avgprodtogamma2 ** (gamma2 - 1) * tau[:, t]\n",
        "        tau[:, t] = np.maximum(tau[:, t], eps_pos)\n",
        "        tau[:, t] = np.minimum(tau[:, t], 1e300)\n",
        "\n",
        "        # Calculate utility\n",
        "        u[:, t] = m2 * l[:, t] ** Omega * (kappa1 ** (1 / Omega) * \\\n",
        "                  ((mu + gamma1 / ksi) / (gamma1 / ksi) * nu) ** (gamma1 / (ksi * gamma2)) * \\\n",
        "                  (np.sum(tau[:, t]) / n) ** (1 / theta * (1 - 1 / gamma2)) * \\\n",
        "                  (lbar / denom) ** (1 / theta - 2 * lambda_ + (alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta) / theta - Omega - gamma1 / (ksi * gamma2)))\n",
        "        u[:, t][~np.isfinite(u[:, t])] = 0\n",
        "\n",
        "        # Calculate real GDP per capita using equation (22)\n",
        "        realgdp[:, t] = u[:, t] / a_norm * l[:, t] ** lambda_\n",
        "\n",
        "        # Calculate innovation using equation (12) and (13)\n",
        "        phi[:, t] = (gamma1 / (nu * (gamma1 + mu * ksi))) ** (1 / ksi) * l[:, t] ** (1 / ksi)\n",
        "\n",
        "        # Calculate wage using equation (23)\n",
        "        w[:, t] = a_norm ** (-theta / (1 + 2 * theta)) * u[:, t] ** (theta / (1 + 2 * theta)) * H ** (-1 / (1 + 2 * theta)) * \\\n",
        "                  tau[:, t] ** (1 / (1 + 2 * theta)) * l[:, t] ** ((alpha - 1 + (lambda_ + gamma1 / ksi - (1 - mu)) * theta) / (1 + 2 * theta))\n",
        "\n",
        "        # Normalize wages relative to Princeton, NJ (Python index adjustment)\n",
        "        w[:, t] = w[:, t] / w[3198, t]  # Adjust index as necessary for your data\n",
        "\n",
        "    # Handle NaN values\n",
        "    realgdp[np.isnan(realgdp)] = 0\n",
        "    tau[np.isnan(tau)] = 0\n",
        "    phi[np.isnan(phi)] = 0\n",
        "    w[np.isnan(w)] = 0\n",
        "    u[np.isnan(u)] = 0\n",
        "    l[np.isnan(l)] = 0\n",
        "\n",
        "    return l, u, w, tau, phi, realgdp\n"
      ],
      "metadata": {
        "id": "4s7eBo1UN0Xy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from pathlib import Path\n",
        "\n",
        "def maps(series1, series2, series3, series4, t, earth_indices=None):\n",
        "    \"\"\"\n",
        "    Creates 4 maps at time t.\n",
        "    The series must be in order:\n",
        "    - series1: l(t)\n",
        "    - series2: u(t)\n",
        "    - series3: prod(t)\n",
        "    - series4: realgdp(t)\n",
        "    \"\"\"\n",
        "    if earth_indices is None:\n",
        "        from init import earth_indices as _earth_indices\n",
        "        earth_indices = _earth_indices\n",
        "\n",
        "    # Take logs of variables\n",
        "    series1 = np.log(series1)\n",
        "    series2 = np.log(series2)\n",
        "    series3 = np.log(series3)\n",
        "    series4 = np.log(series4)\n",
        "\n",
        "    # Define titles for the plots\n",
        "    titles = [\n",
        "        'Log population density, time {}'.format(t),\n",
        "        'Log utility, time {}'.format(t),\n",
        "        'Log productivity, time {}'.format(t),\n",
        "        'Log real GDP per capita, time {}'.format(t)\n",
        "    ]\n",
        "\n",
        "    # Define title names for saving files\n",
        "    title_names = ['PD', 'U', 'PR', 'RO']\n",
        "\n",
        "    # Plot each figure\n",
        "    for i, (series, title, title_name) in enumerate(zip([series1, series2, series3, series4], titles, title_names), start=1):\n",
        "        plt.figure()\n",
        "\n",
        "        # Create the map array\n",
        "        varm = np.full((180, 360), -np.inf)\n",
        "        varm.flat[earth_indices] = series\n",
        "\n",
        "        # Set color limits based on the series and time\n",
        "        if i == 1:\n",
        "            vmin, vmax = -10, 21\n",
        "        elif i == 3:\n",
        "            if t == 1:\n",
        "                vmin, vmax = -3, 7\n",
        "            elif t == 600:\n",
        "                vmin, vmax = 11, 21\n",
        "            else:\n",
        "                vmin, vmax = None, None\n",
        "        elif i == 4:\n",
        "            if t == 1:\n",
        "                vmin, vmax = -4, 3\n",
        "            else:\n",
        "                vmin, vmax = None, None\n",
        "        else:\n",
        "            vmin, vmax = None, None\n",
        "\n",
        "        # Plot the map\n",
        "        plt.imshow(varm, cmap='jet', vmin=vmin, vmax=vmax)\n",
        "        plt.colorbar(label='Value', orientation='vertical')\n",
        "        plt.title(title)\n",
        "\n",
        "        # Save the output to disk\n",
        "        Path('Maps').mkdir(parents=True, exist_ok=True)\n",
        "        filename = 'Maps/{}_NF_{}_1000.png'.format(title_name, t)\n",
        "        plt.savefig(filename)\n",
        "        plt.close()  # Close the figure to avoid memory issues\n"
      ],
      "metadata": {
        "id": "sJCA3NlTN8D1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# from maps import maps\n",
        "# import init\n",
        "from pathlib import Path\n",
        "\n",
        "def plots(H, realgdp_w, u_w, u2_w, prod_w, l, u, tau, realgdp):\n",
        "    global m2, earth_indices, tail_bands, alpha, theta, Omega\n",
        "    alpha = init.alpha\n",
        "    theta = init.theta\n",
        "\n",
        "    T = int(len(realgdp_w))\n",
        "\n",
        "    # Calculate world productivity and real GDP, correlations\n",
        "    prworld = prod_w\n",
        "    rgdpworld = realgdp_w\n",
        "    uworld = u_w\n",
        "    u2world = u2_w\n",
        "    prgrowth = np.zeros(T)\n",
        "    rgdpgrowth = np.zeros(T)\n",
        "    ugrowth = np.zeros(T)\n",
        "    u2growth = np.zeros(T)\n",
        "    corr_rgdppop = np.zeros((T, 2, 2))\n",
        "    corr_prpop = np.zeros((T, 2, 2))\n",
        "    corr_prrgdp = np.zeros((T, 2, 2))\n",
        "\n",
        "    for t in range(T):\n",
        "        if t > 0:\n",
        "            prgrowth[t] = prworld[t] / prworld[t - 1]\n",
        "            rgdpgrowth[t] = rgdpworld[t] / rgdpworld[t - 1]\n",
        "            ugrowth[t] = uworld[t] / uworld[t - 1]\n",
        "            u2growth[t] = u2world[t] / u2world[t - 1]\n",
        "\n",
        "        rgdp_vector = realgdp[:, t]\n",
        "        pop_vector = l[:, t]\n",
        "        pr_vector = (tau[:, t] * l[:, t] ** alpha) ** (1 / theta)\n",
        "\n",
        "        rgdp_vector = rgdp_vector[H > 0]\n",
        "        pop_vector = pop_vector[H > 0]\n",
        "        pr_vector = pr_vector[H > 0]\n",
        "\n",
        "        corr_rgdppop[t, :, :] = np.corrcoef(np.log(rgdp_vector), np.log(pop_vector))\n",
        "        corr_prpop[t, :, :] = np.corrcoef(np.log(pr_vector), np.log(pop_vector))\n",
        "        corr_prrgdp[t, :, :] = np.corrcoef(np.log(pr_vector), np.log(rgdp_vector))\n",
        "\n",
        "    # Time series plots\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "    axs[0, 0].plot(range(1, T), prgrowth[1:T])\n",
        "    axs[0, 0].set_title('Growth rate of productivity')\n",
        "    axs[0, 0].set_xlabel('Time')\n",
        "\n",
        "    axs[0, 1].plot(range(1, T), rgdpgrowth[1:T])\n",
        "    axs[0, 1].set_title('Growth rate of real GDP')\n",
        "    axs[0, 1].set_xlabel('Time')\n",
        "\n",
        "    axs[0, 2].plot(range(1, T), ugrowth[1:T])\n",
        "    axs[0, 2].set_title('Growth rate of utility (u)')\n",
        "    axs[0, 2].set_xlabel('Time')\n",
        "\n",
        "    axs[1, 0].plot(range(T), np.log(prworld[:T]))\n",
        "    axs[1, 0].set_title('Ln world average productivity')\n",
        "    axs[1, 0].set_xlabel('Time')\n",
        "\n",
        "    axs[1, 1].plot(range(T), np.log(rgdpworld[:T]))\n",
        "    axs[1, 1].set_title('Ln world average real GDP')\n",
        "    axs[1, 1].set_xlabel('Time')\n",
        "\n",
        "    axs[1, 2].plot(range(T), np.log(uworld[:T]))\n",
        "    axs[1, 2].set_title('Ln world utility (u)')\n",
        "    axs[1, 2].set_xlabel('Time')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    Path('Output').mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig('Output/world_aggregates.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Additional Time series plots\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    axs[0, 0].plot(range(1, T), ugrowth[1:T])\n",
        "    axs[0, 0].set_title('Growth rate of utility (u)')\n",
        "    axs[0, 0].set_xlabel('Time')\n",
        "\n",
        "    axs[0, 1].plot(range(2, T), u2growth[2:T])\n",
        "    axs[0, 1].set_title('Growth rate of E(u*epsilon)')\n",
        "    axs[0, 1].set_xlabel('Time')\n",
        "\n",
        "    axs[1, 0].plot(range(T), np.log(uworld[:T]))\n",
        "    axs[1, 0].set_title('Ln world utility (u)')\n",
        "    axs[1, 0].set_xlabel('Time')\n",
        "\n",
        "    axs[1, 1].plot(range(T), np.log(u2world[:T]))\n",
        "    axs[1, 1].set_title('Ln E(u*epsilon)')\n",
        "    axs[1, 1].set_xlabel('Time')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    Path('Output').mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig('Output/world_utility.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Correlation plots\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axs[0].plot(corr_rgdppop[:, 0, 1])\n",
        "    axs[0].set_title('Corr (log real GDP per capita, log population density)')\n",
        "    axs[0].set_xlabel('Time')\n",
        "\n",
        "    axs[1].plot(corr_prpop[:, 0, 1])\n",
        "    axs[1].set_title('Corr (log productivity, log population density)')\n",
        "    axs[1].set_xlabel('Time')\n",
        "\n",
        "    axs[2].plot(corr_prrgdp[:, 0, 1])\n",
        "    axs[2].set_title('Corr (log productivity, log real GDP per capita)')\n",
        "    axs[2].set_xlabel('Time')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    Path('Output').mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig('Output/correlations.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Cell-level maps\n",
        "    if T >= 1:\n",
        "        maps(l[:, 0], u[:, 0], (tau[:, 0] * l[:, 0] ** alpha) ** (1 / theta), realgdp[:, 0], 1)\n",
        "    if T >= 200:\n",
        "        maps(l[:, 199], u[:, 199], (tau[:, 199] * l[:, 199] ** alpha) ** (1 / theta), realgdp[:, 199], 200)\n",
        "    if T >= 600:\n",
        "        maps(l[:, 599], u[:, 599], (tau[:, 599] * l[:, 599] ** alpha) ** (1 / theta), realgdp[:, 599], 600)\n"
      ],
      "metadata": {
        "id": "mTM7oiTNN2Yt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from scipy.stats import pearsonr\n",
        "# from model import model\n",
        "\n",
        "def accumarray(indices, values, size):\n",
        "    # A replacement for MATLAB's accumarray\n",
        "    result = np.zeros(size)\n",
        "    for idx, value in zip(indices, values):\n",
        "        j = int(idx) - 1\n",
        "        if 0 <= j < size:\n",
        "            result[j] += value\n",
        "    return result\n",
        "\n",
        "def results(H, T, vars):\n",
        "    # Global variables\n",
        "    global a, a_norm, m2, C_vect, pop0, pop5, pop5_fertadj, beta, n, H0, earth_indices, alpha, theta, Omega\n",
        "    H0, a, a_norm, m2, C_vect, _, pop0, pop5, pop5_fertadj, _, _, _, _, n, earth_indices, _, _, _, beta, _, _, alpha, theta, Omega = vars\n",
        "\n",
        "    # Initialize output arrays\n",
        "    realgdp_w = np.zeros(T)\n",
        "    u_w = np.zeros(T)\n",
        "    u2_w = np.zeros(T)\n",
        "    prod_w = np.zeros(T)\n",
        "    phi_w = np.zeros(T)\n",
        "    PDV_u_w = 0\n",
        "    PDV_u2_w = 0\n",
        "    PDV_realgdp_w = 0\n",
        "\n",
        "    # Simulate the model\n",
        "    l, w, u, tau, phi, realgdp = model(H, T, vars)\n",
        "\n",
        "    # Calculate correlations - Cell Level\n",
        "    print('CORRELATIONS - CELL LEVEL')\n",
        "    corr_pop5 = pearsonr(pop5[earth_indices], H * l[:, 4])\n",
        "    corr_log_pop5 = pearsonr(np.log(pop5[earth_indices]), np.log(H * l[:, 4]))\n",
        "    corr_pop5_diff = pearsonr(pop5[earth_indices] - pop0[earth_indices], H * l[:, 4] - pop0[earth_indices])\n",
        "    corr_log_pop5_diff = pearsonr(np.log(pop5[earth_indices]) - np.log(pop0[earth_indices]), np.log(H * l[:, 4]) - np.log(pop0[earth_indices]))\n",
        "\n",
        "    print('CORRELATIONS - COUNTRY LEVEL')\n",
        "    pop5_ctry_d = accumarray(C_vect, pop5[earth_indices], 168)\n",
        "    pop5_ctry_m = accumarray(C_vect, H * l[:, 4], 168)\n",
        "    pop0_ctry = accumarray(C_vect, pop0[earth_indices], 168)\n",
        "    corr_pop5_ctry_d = pearsonr(pop5_ctry_d, pop5_ctry_m)\n",
        "    corr_log_pop5_ctry_d = pearsonr(np.log(pop5_ctry_d), np.log(pop5_ctry_m))\n",
        "    corr_pop5_ctry_diff = pearsonr(pop5_ctry_d - pop0_ctry, pop5_ctry_m - pop0_ctry)\n",
        "    corr_log_pop5_ctry_diff = pearsonr(np.log(pop5_ctry_d) - np.log(pop0_ctry), np.log(pop5_ctry_m) - np.log(pop0_ctry))\n",
        "\n",
        "    # Fertility-Adjusted Correlations - Cell Level\n",
        "    print('CORRELATIONS (FERTILITY-ADJUSTED) - CELL LEVEL')\n",
        "    corr_pop5_fertadj = pearsonr(pop5_fertadj[earth_indices], H * l[:, 4])\n",
        "    corr_log_pop5_fertadj = pearsonr(np.log(pop5_fertadj[earth_indices]), np.log(H * l[:, 4]))\n",
        "    corr_pop5_fertadj_diff = pearsonr(pop5_fertadj[earth_indices] - pop0[earth_indices], H * l[:, 4] - pop0[earth_indices])\n",
        "    corr_log_pop5_fertadj_diff = pearsonr(np.log(pop5_fertadj[earth_indices]) - np.log(pop0[earth_indices]), np.log(H * l[:, 4]) - np.log(pop0[earth_indices]))\n",
        "\n",
        "    print('CORRELATIONS (FERTILITY-ADJUSTED) - COUNTRY LEVEL')\n",
        "    pop5_fertadj_ctry = accumarray(C_vect, pop5_fertadj[earth_indices], 168)\n",
        "    corr_pop5_fertadj_ctry = pearsonr(pop5_fertadj_ctry, pop5_ctry_m)\n",
        "    corr_log_pop5_fertadj_ctry = pearsonr(np.log(pop5_fertadj_ctry), np.log(pop5_ctry_m))\n",
        "    corr_pop5_fertadj_ctry_diff = pearsonr(pop5_fertadj_ctry - pop0_ctry, pop5_ctry_m - pop0_ctry)\n",
        "    corr_log_pop5_fertadj_ctry_diff = pearsonr(np.log(pop5_fertadj_ctry) - np.log(pop0_ctry), np.log(pop5_ctry_m) - np.log(pop0_ctry))\n",
        "\n",
        "    # Compute world aggregates\n",
        "    u2 = np.zeros((n, T))\n",
        "    m1 = np.power(m2, -1)\n",
        "    for t in range(T):\n",
        "        u2[:, t] = np.sum(np.power(u[:, t], 1 / Omega) * np.power(m2, -1 / Omega)) ** Omega * m2\n",
        "        u_w[t] = np.sum(u[:, t] * H * l[:, t])\n",
        "        u2_w[t] = np.sum(u2[:, t] * H * l[:, t])\n",
        "        realgdp_w[t] = np.sum(realgdp[:, t] * H * l[:, t])\n",
        "        prod_w[t] = np.sum(np.power(tau[:, t] * H * np.power(l[:, t], 1 + alpha), 1 / theta))\n",
        "        phi_w[t] = np.sum(phi[:, t] * H * l[:, t])\n",
        "        PDV_u_w += beta ** t * u_w[t]\n",
        "        PDV_u2_w += beta ** t * u2_w[t]\n",
        "        PDV_realgdp_w += beta ** t * realgdp_w[t]\n",
        "\n",
        "    if beta * u_w[-1] / u_w[-2] < 1:\n",
        "        PDV_u_w += (beta ** T * u_w[-1] ** 2 / u_w[-2]) / (1 - beta * u_w[-1] / u_w[-2])\n",
        "    else:\n",
        "        PDV_u_w = np.nan\n",
        "\n",
        "    if beta * u2_w[-1] / u2_w[-2] < 1:\n",
        "        PDV_u2_w += (beta ** T * u2_w[-1] ** 2 / u2_w[-2]) / (1 - beta * u2_w[-1] / u2_w[-2])\n",
        "    else:\n",
        "        PDV_u2_w = np.nan\n",
        "\n",
        "    if beta * realgdp_w[-1] / realgdp_w[-2] < 1:\n",
        "        PDV_realgdp_w += (beta ** T * realgdp_w[-1] ** 2 / realgdp_w[-2]) / (1 - beta * realgdp_w[-1] / realgdp_w[-2])\n",
        "    else:\n",
        "        PDV_realgdp_w = np.nan\n",
        "\n",
        "    # Share of migrants - Cell Level\n",
        "    migr_cell = np.zeros(T)\n",
        "    for t in range(T):\n",
        "        summ = 0\n",
        "        for j in range(n):\n",
        "            if t == 0:\n",
        "                if H[j] * l[j, 0] > pop0[earth_indices[j]]:\n",
        "                    summ += H[j] * l[j, 0] - pop0[earth_indices[j]]\n",
        "            else:\n",
        "                if H[j] * l[j, t] > H[j] * l[j, t - 1]:\n",
        "                    summ += H[j] * l[j, t] - H[j] * l[j, t - 1]\n",
        "        migr_cell[t] = summ / np.sum(pop0)\n",
        "\n",
        "    migr_ctry = np.zeros(T)\n",
        "    pop_ctry_m = np.zeros((168, T))\n",
        "    for t in range(T):\n",
        "        pop_ctry_m[:, t] = accumarray(C_vect, H * l[:, t], 168)\n",
        "        summ = 0\n",
        "        for i in range(168):\n",
        "            if t == 0:\n",
        "                if pop_ctry_m[i, 0] > pop0_ctry[i]:\n",
        "                    summ += pop_ctry_m[i, 0] - pop0_ctry[i]\n",
        "            else:\n",
        "                if pop_ctry_m[i, t] > pop_ctry_m[i, t - 1]:\n",
        "                    summ += pop_ctry_m[i, t] - pop_ctry_m[i, t - 1]\n",
        "        migr_ctry[t] = summ / np.sum(pop0_ctry)\n",
        "\n",
        "    return realgdp_w, u_w, u2_w, prod_w, phi_w, PDV_u_w, PDV_u2_w, PDV_realgdp_w, migr_cell, migr_ctry, l, u, u2, tau, realgdp\n"
      ],
      "metadata": {
        "id": "26mbgUNYN4Ux"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# from init import initialize\n",
        "# from results import results\n",
        "# from backward import backward\n",
        "# from plots import plots\n",
        "import time\n",
        "_program_start_time = time.perf_counter()\n",
        "\n",
        "global H0, a, a_norm, m2, C_vect, tau0, pop0, pop5, pop5_fertadj, popminus5, popminus10, ubar, trmult_reduced, n, earth_indices, indicator_sea, subs, subs_vect, beta, tail_bands, ind_islands, alpha, theta, Omega\n",
        "\n",
        "# Initialize model\n",
        "vars = initialize(1)\n",
        "H0, a, a_norm, m2, C_vect, tau0, pop0, pop5, pop5_fertadj, popminus5, popminus10, ubar, trmult_reduced, n, earth_indices, indicator_sea, subs, subs_vect, beta, tail_bands, ind_islands, alpha, theta, Omega = vars\n",
        "JAX_DTYPE = jnp.float32  # or jnp.bfloat16\n",
        "\n",
        "_trmult_np = np.asarray(trmult_reduced)\n",
        "\n",
        "trmult_reduced = TPUDenseMat(_trmult_np, jax_dtype=JAX_DTYPE)\n",
        "\n",
        "print(\"Wrapped init.trmult_reduced for TPU matvec:\",\"shape=\", trmult_reduced.shape, \"dtype=\", JAX_DTYPE)\n",
        "\n",
        "# Distribution of land for simulation\n",
        "H0_arr = np.asarray(H0).reshape(-1)\n",
        "H = H0_arr[earth_indices]\n",
        "\n",
        "# Number of periods\n",
        "nb_per = 600\n",
        "\n",
        "# Run the model and obtain summary statistics\n",
        "results_data = results(H, nb_per, vars)\n",
        "realgdp_w, u_w, u2_w, prod_w, phi_w, PDV_u_w, PDV_u2_w, PDV_realgdp_w, migr_cell, migr_ctry, l, u, u2, tau, realgdp = results_data\n",
        "\n",
        "# Plot time series and maps, and save them\n",
        "plots(H, realgdp_w, u_w, u2_w, prod_w, l, u, tau, realgdp)\n",
        "\n",
        "# Number of periods for backward simulation\n",
        "nb_back = 180\n",
        "\n",
        "# Run model backwards\n",
        "l_b, u_b, w_b, tau_b, phi_b, realgdp_b = backward(H, nb_back, vars)\n",
        "\n",
        "# Calculate correlations\n",
        "def calculate_correlation(x, y):\n",
        "    return np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "print('CORRELATIONS WITH 1995 DATA - CELL LEVEL')\n",
        "print(calculate_correlation(popminus5[earth_indices], H0_arr[earth_indices] * l_b[:, 4]))\n",
        "print(calculate_correlation(np.log(popminus5[earth_indices]), np.log(H0_arr[earth_indices] * l_b[:, 4])))\n",
        "print(calculate_correlation(pop0[earth_indices] - popminus5[earth_indices], pop0[earth_indices] - H0_arr[earth_indices] * l_b[:, 4]))\n",
        "print(calculate_correlation(np.log(pop0[earth_indices]) - np.log(popminus5[earth_indices]), np.log(pop0[earth_indices]) - np.log(H0_arr[earth_indices] * l_b[:, 4])))\n",
        "\n",
        "print('CORRELATIONS WITH 1990 DATA - CELL LEVEL')\n",
        "print(calculate_correlation(popminus10[earth_indices], H0_arr[earth_indices] * l_b[:, 9]))\n",
        "print(calculate_correlation(np.log(popminus10[earth_indices]), np.log(H0_arr[earth_indices] * l_b[:, 9])))\n",
        "print(calculate_correlation(pop0[earth_indices] - popminus10[earth_indices], pop0[earth_indices] - H0_arr[earth_indices] * l_b[:, 9]))\n",
        "print(calculate_correlation(np.log(pop0[earth_indices]) - np.log(popminus10[earth_indices]), np.log(pop0[earth_indices]) - np.log(H0_arr[earth_indices] * l_b[:, 9])))\n",
        "\n",
        "print('CORRELATIONS WITH 1995 DATA - COUNTRY LEVEL')\n",
        "ctry_idx = C_vect.astype(int) - 1\n",
        "popminus5_ctry_d = np.bincount(ctry_idx, weights=popminus5[earth_indices])\n",
        "popminus5_ctry_m = np.bincount(ctry_idx, weights=H0_arr[earth_indices] * l_b[:, 4])\n",
        "pop0_ctry = np.bincount(ctry_idx, weights=pop0[earth_indices])\n",
        "print(calculate_correlation(popminus5_ctry_d, popminus5_ctry_m))\n",
        "print(calculate_correlation(np.log(popminus5_ctry_d), np.log(popminus5_ctry_m)))\n",
        "print(calculate_correlation(pop0_ctry - popminus5_ctry_d, pop0_ctry - popminus5_ctry_m))\n",
        "print(calculate_correlation(np.log(pop0_ctry) - np.log(popminus5_ctry_d), np.log(pop0_ctry) - np.log(popminus5_ctry_m)))\n",
        "\n",
        "print('CORRELATIONS WITH 1990 DATA - COUNTRY LEVEL')\n",
        "popminus10_ctry_d = np.bincount(ctry_idx, weights=popminus10[earth_indices])\n",
        "popminus10_ctry_m = np.bincount(ctry_idx, weights=H0_arr[earth_indices] * l_b[:, 9])\n",
        "print(calculate_correlation(popminus10_ctry_d, popminus10_ctry_m))\n",
        "print(calculate_correlation(np.log(popminus10_ctry_d), np.log(popminus10_ctry_m)))\n",
        "print(calculate_correlation(pop0_ctry - popminus10_ctry_d, pop0_ctry - popminus10_ctry_m))\n",
        "print(calculate_correlation(np.log(pop0_ctry) - np.log(popminus10_ctry_d), np.log(pop0_ctry) - np.log(popminus10_ctry_m)))\n",
        "\n",
        "# Save all the output to disk\n",
        "Path('Output').mkdir(parents=True, exist_ok=True)\n",
        "sio.savemat('Output/realgdp_w.mat', {'realgdp_w': realgdp_w})\n",
        "sio.savemat('Output/u_w.mat', {'u_w': u_w})\n",
        "sio.savemat('Output/u2_w.mat', {'u2_w': u2_w})\n",
        "sio.savemat('Output/prod_w.mat', {'prod_w': prod_w})\n",
        "sio.savemat('Output/phi_w.mat', {'phi_w': phi_w})\n",
        "sio.savemat('Output/PDV_u_w.mat', {'PDV_u_w': PDV_u_w})\n",
        "sio.savemat('Output/PDV_u2_w.mat', {'PDV_u2_w': PDV_u2_w})\n",
        "sio.savemat('Output/PDV_realgdp_w.mat', {'PDV_realgdp_w': PDV_realgdp_w})\n",
        "sio.savemat('Output/migr_cell.mat', {'migr_cell': migr_cell})\n",
        "sio.savemat('Output/migr_ctry.mat', {'migr_ctry': migr_ctry})\n",
        "sio.savemat('Output/l.mat', {'l': l})\n",
        "sio.savemat('Output/u.mat', {'u': u})\n",
        "sio.savemat('Output/realgdp.mat', {'realgdp': realgdp})\n",
        "sio.savemat('Output/tau.mat', {'tau': tau})\n",
        "sio.savemat('Output/l_b.mat', {'l_b': l_b})\n",
        "_program_total_time = (time.perf_counter() - _program_start_time) * 1e3\n",
        "print(f\"\\nTOTAL RUNTIME: { _program_total_time:.9f} ms ({_program_total_time/1000:.9f} s)\")\n"
      ],
      "metadata": {
        "id": "djyuxeoLODyV",
        "outputId": "e9b85e4c-6f27-4e2c-8feb-e958d6301a85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapped init.trmult_reduced for TPU matvec: shape= (17048, 17048) dtype= <class 'jax.numpy.float32'>\n",
            "t=1\n",
            "TOTAL IMPORTS TO WORLD GDP\n",
            "4.0523494250654934e-05\n",
            "t=2\n",
            "t=3\n",
            "t=4\n",
            "t=5\n",
            "t=6\n",
            "t=7\n",
            "t=8\n",
            "t=9\n",
            "t=10\n",
            "t=11\n",
            "t=12\n",
            "t=13\n",
            "t=14\n",
            "t=15\n",
            "t=16\n",
            "t=17\n",
            "t=18\n",
            "t=19\n",
            "t=20\n",
            "t=21\n",
            "t=22\n",
            "t=23\n",
            "t=24\n",
            "t=25\n",
            "t=26\n",
            "t=27\n",
            "t=28\n",
            "t=29\n",
            "t=30\n",
            "t=31\n",
            "t=32\n",
            "t=33\n",
            "t=34\n",
            "t=35\n",
            "t=36\n",
            "t=37\n",
            "t=38\n",
            "t=39\n",
            "t=40\n",
            "t=41\n",
            "t=42\n",
            "t=43\n",
            "t=44\n",
            "t=45\n",
            "t=46\n",
            "t=47\n",
            "t=48\n",
            "t=49\n",
            "t=50\n",
            "t=51\n",
            "t=52\n",
            "t=53\n",
            "t=54\n",
            "t=55\n",
            "t=56\n",
            "t=57\n",
            "t=58\n",
            "t=59\n",
            "t=60\n",
            "t=61\n",
            "t=62\n",
            "t=63\n",
            "t=64\n",
            "t=65\n",
            "t=66\n",
            "t=67\n",
            "t=68\n",
            "t=69\n",
            "t=70\n",
            "t=71\n",
            "t=72\n",
            "t=73\n",
            "t=74\n",
            "t=75\n",
            "t=76\n",
            "t=77\n",
            "t=78\n",
            "t=79\n",
            "t=80\n",
            "t=81\n",
            "t=82\n",
            "t=83\n",
            "t=84\n",
            "t=85\n",
            "t=86\n",
            "t=87\n",
            "t=88\n",
            "t=89\n",
            "t=90\n",
            "t=91\n",
            "t=92\n",
            "t=93\n",
            "t=94\n",
            "t=95\n",
            "t=96\n",
            "t=97\n",
            "t=98\n",
            "t=99\n",
            "t=100\n",
            "t=101\n",
            "t=102\n",
            "t=103\n",
            "t=104\n",
            "t=105\n",
            "t=106\n",
            "t=107\n",
            "t=108\n",
            "t=109\n",
            "t=110\n",
            "t=111\n",
            "t=112\n",
            "t=113\n",
            "t=114\n",
            "t=115\n",
            "t=116\n",
            "t=117\n",
            "t=118\n",
            "t=119\n",
            "t=120\n",
            "t=121\n",
            "t=122\n",
            "t=123\n",
            "t=124\n",
            "t=125\n",
            "t=126\n",
            "t=127\n",
            "t=128\n",
            "t=129\n",
            "t=130\n",
            "t=131\n",
            "t=132\n",
            "t=133\n",
            "t=134\n",
            "t=135\n",
            "t=136\n",
            "t=137\n",
            "t=138\n",
            "t=139\n",
            "t=140\n",
            "t=141\n",
            "t=142\n",
            "t=143\n",
            "t=144\n",
            "t=145\n",
            "t=146\n",
            "t=147\n",
            "t=148\n",
            "t=149\n",
            "t=150\n",
            "t=151\n",
            "t=152\n",
            "t=153\n",
            "t=154\n",
            "t=155\n",
            "t=156\n",
            "t=157\n",
            "t=158\n",
            "t=159\n",
            "t=160\n",
            "t=161\n",
            "t=162\n",
            "t=163\n",
            "t=164\n",
            "t=165\n",
            "t=166\n",
            "t=167\n",
            "t=168\n",
            "t=169\n",
            "t=170\n",
            "t=171\n",
            "t=172\n",
            "t=173\n",
            "t=174\n",
            "t=175\n",
            "t=176\n",
            "t=177\n",
            "t=178\n",
            "t=179\n",
            "t=180\n",
            "t=181\n",
            "t=182\n",
            "t=183\n",
            "t=184\n",
            "t=185\n",
            "t=186\n",
            "t=187\n",
            "t=188\n",
            "t=189\n",
            "t=190\n",
            "t=191\n",
            "t=192\n",
            "t=193\n",
            "t=194\n",
            "t=195\n",
            "t=196\n",
            "t=197\n",
            "t=198\n",
            "t=199\n",
            "t=200\n",
            "t=201\n",
            "t=202\n",
            "t=203\n",
            "t=204\n",
            "t=205\n",
            "t=206\n",
            "t=207\n",
            "t=208\n",
            "t=209\n",
            "t=210\n",
            "t=211\n",
            "t=212\n",
            "t=213\n",
            "t=214\n",
            "t=215\n",
            "t=216\n",
            "t=217\n",
            "t=218\n",
            "t=219\n",
            "t=220\n",
            "t=221\n",
            "t=222\n",
            "t=223\n",
            "t=224\n",
            "t=225\n",
            "t=226\n",
            "t=227\n",
            "t=228\n",
            "t=229\n",
            "t=230\n",
            "t=231\n",
            "t=232\n",
            "t=233\n",
            "t=234\n",
            "t=235\n",
            "t=236\n",
            "t=237\n",
            "t=238\n",
            "t=239\n",
            "t=240\n",
            "t=241\n",
            "t=242\n",
            "t=243\n",
            "t=244\n",
            "t=245\n",
            "t=246\n",
            "t=247\n",
            "t=248\n",
            "t=249\n",
            "t=250\n",
            "t=251\n",
            "t=252\n",
            "t=253\n",
            "t=254\n",
            "t=255\n",
            "t=256\n",
            "t=257\n",
            "t=258\n",
            "t=259\n",
            "t=260\n",
            "t=261\n",
            "t=262\n",
            "t=263\n",
            "t=264\n",
            "t=265\n",
            "t=266\n",
            "t=267\n",
            "t=268\n",
            "t=269\n",
            "t=270\n",
            "t=271\n",
            "t=272\n",
            "t=273\n",
            "t=274\n",
            "t=275\n",
            "t=276\n",
            "t=277\n",
            "t=278\n",
            "t=279\n",
            "t=280\n",
            "t=281\n",
            "t=282\n",
            "t=283\n",
            "t=284\n",
            "t=285\n",
            "t=286\n",
            "t=287\n",
            "t=288\n",
            "t=289\n",
            "t=290\n",
            "t=291\n",
            "t=292\n",
            "t=293\n",
            "t=294\n",
            "t=295\n",
            "t=296\n",
            "t=297\n",
            "t=298\n",
            "t=299\n",
            "t=300\n",
            "t=301\n",
            "t=302\n",
            "t=303\n",
            "t=304\n",
            "t=305\n",
            "t=306\n",
            "t=307\n",
            "t=308\n",
            "t=309\n",
            "t=310\n",
            "t=311\n",
            "t=312\n",
            "t=313\n",
            "t=314\n",
            "t=315\n",
            "t=316\n",
            "t=317\n",
            "t=318\n",
            "t=319\n",
            "t=320\n",
            "t=321\n",
            "t=322\n",
            "t=323\n",
            "t=324\n",
            "t=325\n",
            "t=326\n",
            "t=327\n",
            "t=328\n",
            "t=329\n",
            "t=330\n",
            "t=331\n",
            "t=332\n",
            "t=333\n",
            "t=334\n",
            "t=335\n",
            "t=336\n",
            "t=337\n",
            "t=338\n",
            "t=339\n",
            "t=340\n",
            "t=341\n",
            "t=342\n",
            "t=343\n",
            "t=344\n",
            "t=345\n",
            "t=346\n",
            "t=347\n",
            "t=348\n",
            "t=349\n",
            "t=350\n",
            "t=351\n",
            "t=352\n",
            "t=353\n",
            "t=354\n",
            "t=355\n",
            "t=356\n",
            "t=357\n",
            "t=358\n",
            "t=359\n",
            "t=360\n",
            "t=361\n",
            "t=362\n",
            "t=363\n",
            "t=364\n",
            "t=365\n",
            "t=366\n",
            "t=367\n",
            "t=368\n",
            "t=369\n",
            "t=370\n",
            "t=371\n",
            "t=372\n",
            "t=373\n",
            "t=374\n",
            "t=375\n",
            "t=376\n",
            "t=377\n",
            "t=378\n",
            "t=379\n",
            "t=380\n",
            "t=381\n",
            "t=382\n",
            "t=383\n",
            "t=384\n",
            "t=385\n",
            "t=386\n",
            "t=387\n",
            "t=388\n",
            "t=389\n",
            "t=390\n",
            "t=391\n",
            "t=392\n",
            "t=393\n",
            "t=394\n",
            "t=395\n",
            "t=396\n",
            "t=397\n",
            "t=398\n",
            "t=399\n",
            "t=400\n",
            "t=401\n",
            "t=402\n",
            "t=403\n",
            "t=404\n",
            "t=405\n",
            "t=406\n",
            "t=407\n",
            "t=408\n",
            "t=409\n",
            "t=410\n",
            "t=411\n",
            "t=412\n",
            "t=413\n",
            "t=414\n",
            "t=415\n",
            "t=416\n",
            "t=417\n",
            "t=418\n",
            "t=419\n",
            "t=420\n",
            "t=421\n",
            "t=422\n",
            "t=423\n",
            "t=424\n",
            "t=425\n",
            "t=426\n",
            "t=427\n",
            "t=428\n",
            "t=429\n",
            "t=430\n",
            "t=431\n",
            "t=432\n",
            "t=433\n",
            "t=434\n",
            "t=435\n",
            "t=436\n",
            "t=437\n",
            "t=438\n",
            "t=439\n",
            "t=440\n",
            "t=441\n",
            "t=442\n",
            "t=443\n",
            "t=444\n",
            "t=445\n",
            "t=446\n",
            "t=447\n",
            "t=448\n",
            "t=449\n",
            "t=450\n",
            "t=451\n",
            "t=452\n",
            "t=453\n",
            "t=454\n",
            "t=455\n",
            "t=456\n",
            "t=457\n",
            "t=458\n",
            "t=459\n",
            "t=460\n",
            "t=461\n",
            "t=462\n",
            "t=463\n",
            "t=464\n",
            "t=465\n",
            "t=466\n",
            "t=467\n",
            "t=468\n",
            "t=469\n",
            "t=470\n",
            "t=471\n",
            "t=472\n",
            "t=473\n",
            "t=474\n",
            "t=475\n",
            "t=476\n",
            "t=477\n",
            "t=478\n",
            "t=479\n",
            "t=480\n",
            "t=481\n",
            "t=482\n",
            "t=483\n",
            "t=484\n",
            "t=485\n",
            "t=486\n",
            "t=487\n",
            "t=488\n",
            "t=489\n",
            "t=490\n",
            "t=491\n",
            "t=492\n",
            "t=493\n",
            "t=494\n",
            "t=495\n",
            "t=496\n",
            "t=497\n",
            "t=498\n",
            "t=499\n",
            "t=500\n",
            "t=501\n",
            "t=502\n",
            "t=503\n",
            "t=504\n",
            "t=505\n",
            "t=506\n",
            "t=507\n",
            "t=508\n",
            "t=509\n",
            "t=510\n",
            "t=511\n",
            "t=512\n",
            "t=513\n",
            "t=514\n",
            "t=515\n",
            "t=516\n",
            "t=517\n",
            "t=518\n",
            "t=519\n",
            "t=520\n",
            "t=521\n",
            "t=522\n",
            "t=523\n",
            "t=524\n",
            "t=525\n",
            "t=526\n",
            "t=527\n",
            "t=528\n",
            "t=529\n",
            "t=530\n",
            "t=531\n",
            "t=532\n",
            "t=533\n",
            "t=534\n",
            "t=535\n",
            "t=536\n",
            "t=537\n",
            "t=538\n",
            "t=539\n",
            "t=540\n",
            "t=541\n",
            "t=542\n",
            "t=543\n",
            "t=544\n",
            "t=545\n",
            "t=546\n",
            "t=547\n",
            "t=548\n",
            "t=549\n",
            "t=550\n",
            "t=551\n",
            "t=552\n",
            "t=553\n",
            "t=554\n",
            "t=555\n",
            "t=556\n",
            "t=557\n",
            "t=558\n",
            "t=559\n",
            "t=560\n",
            "t=561\n",
            "t=562\n",
            "t=563\n",
            "t=564\n",
            "t=565\n",
            "t=566\n",
            "t=567\n",
            "t=568\n",
            "t=569\n",
            "t=570\n",
            "t=571\n",
            "t=572\n",
            "t=573\n",
            "t=574\n",
            "t=575\n",
            "t=576\n",
            "t=577\n",
            "t=578\n",
            "t=579\n",
            "t=580\n",
            "t=581\n",
            "t=582\n",
            "t=583\n",
            "t=584\n",
            "t=585\n",
            "t=586\n",
            "t=587\n",
            "t=588\n",
            "t=589\n",
            "t=590\n",
            "t=591\n",
            "t=592\n",
            "t=593\n",
            "t=594\n",
            "t=595\n",
            "t=596\n",
            "t=597\n",
            "t=598\n",
            "t=599\n",
            "t=600\n",
            "TOTAL IMPORTS TO WORLD GDP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3s7VEN-hOIl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}